x-presto-native-worker-gpu: &gpu_worker_base
  extends:
    file: ../docker-compose.common.yml
    service: presto-base-native-worker
  image: presto-native-worker-gpu:latest
  build:
    args:
      - GPU=ON
  runtime: nvidia
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
  cap_add:
    - IPC_LOCK
  pid: host
  ulimits:
    memlock: -1
    stack: 67108864
  shm_size: 1g
  environment:
    - NVIDIA_VISIBLE_DEVICES=all
    - PROFILE=${PROFILE}
    - PROFILE_ARGS=${PROFILE_ARGS}
  depends_on:
    - presto-coordinator
  volumes:
    - ../config/generated/gpu/etc_common:/opt/presto-server/etc
    - ../config/generated/gpu/etc_worker/node.properties:/opt/presto-server/etc/node.properties
    - ../config/generated/gpu/etc_worker/config_native.properties:/opt/presto-server/etc/config.properties
    - ../config/generated/gpu/etc_worker/catalog/hive.properties:/opt/presto-server/etc/catalog/hive.properties

services:
  presto-coordinator:
    extends:
      file: ../docker-compose.common.yml
      service: presto-base-coordinator
    volumes:
      - ../config/generated/gpu/etc_common:/opt/presto-server/etc
      - ../config/generated/gpu/etc_coordinator/config_native.properties:/opt/presto-server/etc/config.properties
      - ../config/generated/gpu/etc_coordinator/node.properties:/opt/presto-server/etc/node.properties
      - ../config/generated/gpu/etc_coordinator/catalog/hive.properties:/opt/presto-server/etc/catalog/hive.properties

{% if workers %}
  # These workers are generated dynamically; each is pinned to a specific GPU.
{% for gpu_id in workers %}
  presto-native-worker-gpu-{{ loop.index0 }}:
    <<: *gpu_worker_base
    container_name: presto-native-worker-gpu-{{ loop.index0 }}
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES={{ gpu_id }}
      - PROFILE=${PROFILE}
      - PROFILE_ARGS=-t nvtx,cuda,osrt,ucx --cuda-memory-usage=true --cuda-um-cpu-page-faults=true --cuda-um-gpu-page-faults=true --cudabacktrace=true
      - UCX_LOG_LEVEL=info #debug
      - UCX_RNDV_PIPELINE_ERROR_HANDLING=y
      - UCX_TLS=tcp,cuda_copy,cuda_ipc
      - UCX_TCP_CM_REUSEADDR=y
      - UCX_PROTO_INFO=y
      # don't know, leave it for now
      - UCX_TCP_KEEPINTVL=1ms
      - UCX_KEEPALIVE_INTERVAL=1ms
    devices:
      # required for GDS
      - /dev/infiniband/rdma_cm
      - /dev/infiniband/uverbs0
      - /dev/infiniband/uverbs1
      - /dev/infiniband/uverbs2
      - /dev/infiniband/uverbs3
      - /dev/infiniband/uverbs4
      - /dev/infiniband/uverbs5
      - /dev/infiniband/uverbs6
      - /dev/infiniband/uverbs7
      - /dev/infiniband/uverbs8
      - /dev/infiniband/uverbs9

    volumes:
      - ../config/generated/gpu/etc_common:/opt/presto-server/etc
      - ../config/generated/gpu/etc_worker_{{ loop.index0 }}/node.properties:/opt/presto-server/etc/node.properties
      - ../config/generated/gpu/etc_worker_{{ loop.index0 }}/config_native.properties:/opt/presto-server/etc/config.properties
      - ../config/generated/gpu/etc_worker_{{ loop.index0 }}/catalog/hive.properties:/opt/presto-server/etc/catalog/hive.properties
{% endfor %}
{% else %}
  # Default single worker when num-workers is not specified
  presto-native-worker-gpu:
    <<: *gpu_worker_base
    container_name: presto-native-worker-gpu
{% endif %}

