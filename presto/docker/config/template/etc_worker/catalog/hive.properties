# Select the connector implementation. "hive-hadoop2" uses the Hive connector
# backed by Hadoop 2.x libraries which is the default for Presto's Hive support.
connector.name=hive-hadoop2

# Configure the metastore implementation. "file" enables a simple file-based
# metastore suitable for local testing without an external Hive Metastore (HMS).
# See https://prestodb.io/docs/current/installation/deployment.html#configuring-a-file-based-metastore for more details.
hive.metastore=file
# Root directory where the file-based metastore stores table and partition
# metadata. This path is inside the container volume so state persists across
# server restarts during tests.
hive.metastore.catalog.dir=file:/var/lib/presto/data/hive/metastore
# Allow DROP TABLE statements. Enabled to make smoke/perf tests able to reset
# state and clean up artifacts without manual intervention.
hive.allow-drop-table=true

# Control whether Presto can split files for parallel reads. Disable when the
# file compression/format isn't splittable to avoid read failures. TPCH Parquet
# test data commonly uses SNAPPY compression that isn't splittable at the file
# level here, hence this must be false.
hive.file-splittable=false

# Parquet read options
# Limit (in bytes) on total number of bytes to be returned per read, or 0 if there is no limit
parquet.reader.chunk-read-limit=0
# Limit (in bytes) on the amount of memory used for reading and decompressing data or 0 if there is no limit
parquet.reader.pass-read-limit=0

#hive.s3.aws-access-key=XXX
#hive.s3.ssl.enabled=false
#hive.s3.aws-secret-key=YYY
#hive.s3.endpoint=http://172.18.117.51:9000
#hive.s3.path-style-access=true
